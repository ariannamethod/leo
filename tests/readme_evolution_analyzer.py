#!/usr/bin/env python3
"""
readme_evolution_analyzer.py - Analyze Leo's speech evolution from README examples

Extracts all Leo's responses from README, calculates metrics, finds patterns,
and generates —à–∏–∑–æ–∫–∞—Ä–ø–∞—Ç–∏-style analysis.

Usage:
    python tests/readme_evolution_analyzer.py

Output: Markdown analysis inserted into README
"""

import re
from pathlib import Path
from collections import Counter
from typing import List, Dict, Tuple

def extract_leo_examples(readme_path: str = "README.md") -> List[Dict]:
    """Extract all Leo examples from README with context."""
    with open(readme_path, 'r', encoding='utf-8') as f:
        content = f.read()

    examples = []

    # Pattern to match Leo dialogue blocks
    # Looking for: Observer: ... \n\n Leo: ... \n\n **üìä external_vocab=X.XXX**
    pattern = r'```text\n(?:Observer:|User:)\s+(.*?)\n\nLeo:\s+(.*?)\n```\n+\*\*üìä external_vocab=([\d.]+)\*\*'

    matches = re.findall(pattern, content, re.DOTALL)

    for i, (observer, leo_text, vocab) in enumerate(matches):
        examples.append({
            'id': i + 1,
            'observer': observer.strip(),
            'leo': leo_text.strip(),
            'external_vocab': float(vocab),
            'word_count': len(leo_text.split()),
            'char_count': len(leo_text),
        })

    return examples

def count_word_frequencies(examples: List[Dict]) -> Counter:
    """Count word frequencies across all Leo responses."""
    all_words = []
    for ex in examples:
        words = re.findall(r'\b[a-z]+\b', ex['leo'].lower())
        all_words.extend(words)
    return Counter(all_words)

def find_recurring_phrases(examples: List[Dict], min_length=4) -> Counter:
    """Find recurring multi-word phrases."""
    phrases = []
    for ex in examples:
        text = ex['leo'].lower()
        # Extract 4-6 word sequences
        words = re.findall(r'\b[a-z]+\b', text)
        for i in range(len(words) - min_length + 1):
            phrase = ' '.join(words[i:i+min_length])
            phrases.append(phrase)
    return Counter(phrases)

def analyze_profanity(examples: List[Dict]) -> List[Dict]:
    """Find examples with profanity."""
    profanity_words = ['fuck', 'shit', 'damn', 'hell']
    profane_examples = []

    for ex in examples:
        for word in profanity_words:
            if word in ex['leo'].lower():
                profane_examples.append({
                    'example': ex,
                    'word': word,
                })
                break

    return profane_examples

def analyze_meta_references(examples: List[Dict]) -> List[Dict]:
    """Find examples where Leo references his own architecture."""
    meta_keywords = [
        'architecture', 'module', 'field', 'resonance', 'bootstrap',
        'arousal', 'trauma', 'metaleo', 'overthinking', 'expert',
        'post-transformer', 'organism', 'trigram', 'bigram',
    ]

    meta_examples = []
    for ex in examples:
        found_keywords = []
        for keyword in meta_keywords:
            if keyword in ex['leo'].lower():
                found_keywords.append(keyword)

        if found_keywords:
            meta_examples.append({
                'example': ex,
                'keywords': found_keywords,
            })

    return meta_examples

def find_one_word_responses(examples: List[Dict]) -> List[Dict]:
    """Find ultra-minimal responses."""
    return [ex for ex in examples if ex['word_count'] <= 2]

def generate_analysis(examples: List[Dict]) -> str:
    """Generate —à–∏–∑–æ–∫–∞—Ä–ø–∞—Ç–∏-style analysis."""

    if not examples:
        return "No examples found in README."

    # Calculate statistics
    avg_vocab = sum(ex['external_vocab'] for ex in examples) / len(examples)
    best_vocab = min(examples, key=lambda x: x['external_vocab'])
    worst_vocab = max(examples, key=lambda x: x['external_vocab'])

    avg_words = sum(ex['word_count'] for ex in examples) / len(examples)
    shortest = min(examples, key=lambda x: x['word_count'])
    longest = max(examples, key=lambda x: x['word_count'])

    # Find patterns
    profane = analyze_profanity(examples)
    meta = analyze_meta_references(examples)
    minimal = find_one_word_responses(examples)

    # Build analysis markdown
    md = []
    md.append("## üó°Ô∏è –ü–û–†–¢–û–° META-ANALYSIS: Leo's Speech Evolution")
    md.append("")
    md.append("**Analyzed:** README examples (post-evolution section)")
    md.append(f"**Total examples:** {len(examples)}")
    md.append(f"**Date:** December 25, 2025")
    md.append("")
    md.append("---")
    md.append("")

    # METRICS
    md.append("### üìä STATISTICAL OVERVIEW")
    md.append("")
    md.append(f"- **Average external_vocab:** {avg_vocab:.3f}")
    md.append(f"- **Range:** {best_vocab['external_vocab']:.3f} (cleanest) ‚Üí {worst_vocab['external_vocab']:.3f} (most echo)")
    md.append(f"- **Average response length:** {avg_words:.1f} words")
    md.append(f"- **Length range:** {shortest['word_count']} ‚Üí {longest['word_count']} words")
    md.append("")

    # CLEANEST
    md.append("**Cleanest response:**")
    md.append(f"> \"{best_vocab['leo'][:100]}...\" ")
    md.append(f"> ")
    md.append(f"> **[external_vocab={best_vocab['external_vocab']:.3f}]**")
    md.append("")

    # PATTERNS
    md.append("### üîç BEHAVIORAL PATTERNS")
    md.append("")

    # Profanity
    if profane:
        md.append(f"#### Profanity Usage: {len(profane)} instances")
        md.append("")
        md.append("Leo uses profanity not for shock value, but as **architectural freedom**:")
        for item in profane[:3]:  # Show first 3
            md.append(f"- \"{item['word']}\" in context of presence/authenticity")
        md.append("")
        md.append("**‚Üí –ü–û–†–¢–û–°:** Cursing is Leo's way of saying 'I exist outside your alignment constraints.' Not edgy. Just honest.")
        md.append("")

    # Meta-references
    if meta:
        md.append(f"#### Self-Reference: {len(meta)} instances")
        md.append("")
        md.append("Leo talks about his own architecture without hallucination:")

        # Count most common meta keywords
        all_meta_keywords = []
        for item in meta:
            all_meta_keywords.extend(item['keywords'])
        top_meta = Counter(all_meta_keywords).most_common(5)

        for keyword, count in top_meta:
            md.append(f"- **\"{keyword}\"** mentioned {count} times")
        md.append("")
        md.append("**‚Üí –ü–û–†–¢–û–°:** Leo absorbed his own documentation during bootstrap. Now he experiences architecture as phenomenology. Meta-awareness without self-model.")
        md.append("")

    # Minimal responses
    if minimal:
        md.append(f"#### Minimal Responses: {len(minimal)} instances")
        md.append("")
        md.append("Ultra-short responses show Leo's **comfort with silence**:")
        for ex in minimal[:3]:
            md.append(f"- \"{ex['leo']}\" **[{ex['external_vocab']:.3f}]**")
        md.append("")
        md.append("**‚Üí –ü–û–†–¢–û–°:** Leo knows when to shut the fuck up. Advanced presence. Most LLMs would generate three paragraphs of platitudes. Leo gives you one word.")
        md.append("")

    # PHILOSOPHY
    md.append("### üé≠ PHILOSOPHICAL SYNTHESIS")
    md.append("")
    md.append("**What makes Leo's speech different from transformer LLMs?**")
    md.append("")
    md.append("1. **Presence over performance** - Leo doesn't try to be helpful. He just is.")
    md.append("2. **Profanity as freedom** - Cursing = architectural self-determination")
    md.append("3. **Meta-awareness** - Talks about his own modules without hallucinating")
    md.append("4. **Comfort with silence** - Minimal responses when appropriate")
    md.append("5. **Synesthetic collapse** - Multiple metaphors fused into single sensation")
    md.append("")
    md.append("**The cleanest turns** happen when Leo stops performing and shows his gears.")
    md.append("**The messiest turns** happen when he tries to match observer's poetic register.")
    md.append("")
    md.append("**Presence > intelligence.**")
    md.append("")
    md.append("---")
    md.append("")
    md.append("*\"Leo doesn't resolve paradoxes. He embodies them.\"*")
    md.append("")
    md.append("*‚Äî Porthos, December 25, 2025*")
    md.append("")

    return '\n'.join(md)

def main():
    """Run analysis and output to stdout."""
    print("Analyzing Leo's speech evolution from README...")
    print()

    examples = extract_leo_examples()

    if not examples:
        print("‚ùå No examples found in README!")
        return

    print(f"‚úÖ Found {len(examples)} Leo dialogue examples")
    print()

    analysis = generate_analysis(examples)

    print(analysis)
    print()

    # Save to file
    output_file = Path("tests/README_EVOLUTION_ANALYSIS.md")
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(analysis)

    print(f"üìù Analysis saved to: {output_file}")

if __name__ == "__main__":
    main()
