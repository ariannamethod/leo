game.py — sequential playfield for leo (design for Claude Code)

0. Intent

game.py is an optional, lightweight sequencing layer for leo.
	•	It does not generate text.
	•	It does not touch tokens, trigrams or co-occurrence directly.
	•	It operates on episodes + MathState + themes, and learns:
“Given the last 1–2 conversational turns, what type of turn usually comes next?”

It returns soft hints (mode, expert, length, tension), which other modules may use:
	•	expert routing (Resonant Experts),
	•	theme emphasis (ThemeLayer / SANTACLAUS),
	•	length / temperature nudges.

If game.py is missing or fails, leo behaves exactly as now. No hard dependency.

⸻

1. Core concepts

1.1 GameTurn — one conversational move

Abstraction over “what kind of step this was”, built from existing signals.

from dataclasses import dataclass
from typing import Literal, Optional

Role = Literal["human", "leo"]
Mode = Literal["q", "a", "meta", "story", "ack"]
Bucket = Literal["low", "mid", "high"]
ExpertName = Literal["structural", "semantic", "creative", "precise", "wounded"]

@dataclass
class GameTurn:
    role: Role
    mode: Mode                # question / answer / meta / story / short ack
    arousal: Bucket           # from PresencePulse
    trauma: Bucket            # from trauma.level
    entropy: Bucket           # from pulse.entropy
    expert: ExpertName        # which expert actually replied
    theme_id: int             # dominant theme id, or -1 if none
    quality: Bucket           # self-assessed quality bucket (for leo only)

    def to_id(self) -> str:
        """
        Compact, stable identifier for this turn type.

        Example:
            "H:Q:LOW:TRAUMA_LOW:ENT_MID:THEME_-1:EXP_STRUCT:Q_MID"
        """
        return (
            f"{self.role}:{self.mode}:"
            f"A_{self.arousal}:T_{self.trauma}:E_{self.entropy}:"
            f"TH_{self.theme_id}:EX_{self.expert}:Q_{self.quality}"
        )

Bucketization helper (to be implemented in game.py):

def bucketize(x: float, low: float = 0.33, high: float = 0.66) -> Bucket:
    # x assumed in [0,1]
    if x < low:
        return "low"
    if x > high:
        return "high"
    return "mid"

Construction rules (v1):
	•	role:
	•	"human": user message,
	•	"leo": leo’s reply.
	•	mode:
	•	"q": if prompt ends with ? or contains typical question markers,
	•	"ack": very short response / “ok / thanks” style,
	•	"meta": if metaleo / trauma / explicit “who are you / what is leo” pattern (simple heuristic),
	•	"story": long replies with narrative tone,
	•	"a": default answer.
	•	arousal: bucketize(pulse.arousal).
	•	trauma: bucketize(trauma.level) (0.0 if trauma module unavailable).
	•	entropy: bucketize(pulse.entropy).
	•	expert: actual expert name used for reply; for human turns you can set "structural" by default.
	•	theme_id: dominant theme from ThemeLayer, or -1 if none / theme layer off.
	•	quality:
	•	for leo’s own replies: bucketize(quality_score),
	•	for human turns: "mid" constant (we don’t judge the human).

Provide a constructor for convenience:

@classmethod
def from_context(
    cls,
    role: Role,
    mode: Mode,
    math_state: "MathState",
    theme_id: int,
    expert: ExpertName,
    quality_value: Optional[float],
) -> "GameTurn":
    ...

This method should pull arousal, entropy, trauma_level, and map quality_value to bucket (or "mid" if None).

⸻

1.2 GameHint — advisory output

What leo can do with this next.

from dataclasses import dataclass

LengthHint = Literal["short", "medium", "long"]
TensionShift = Literal["softer", "same", "stronger"]

@dataclass
class GameHint:
    mode: Optional[Mode] = None
    preferred_expert: Optional[ExpertName] = None
    target_length: Optional[LengthHint] = None
    tension_shift: Optional[TensionShift] = None
    confidence: float = 0.0  # 0..1

	•	All fields are optional. If confidence is low or data is weak, fields may be None.
	•	Callers must treat this as soft bias. Never as hard rules.

⸻

2. Engine design

2.1 GameEngine API

from pathlib import Path
from typing import Dict, Tuple, List, Optional, Sequence
from collections import Counter

class GameEngine:
    """
    Lightweight A+B->C transition graph over GameTurn IDs.

    - Stores counts and scores for transitions (A,B)->C
    - Keeps minimal global stats (#episodes) for chain length growth
    - All heavy I/O wrapped in try/except and silent on failure
    """

    def __init__(self, db_path: Optional[Path] = None):
        self.db_path = db_path or Path(__file__).parent / "state" / "game.sqlite3"
        self._transitions: Dict[Tuple[str, str], Counter] = {}
        self._single: Counter = Counter()
        self._episode_count: int = 0

        # in-memory last turns per conversation
        self._last_turns: Dict[str, List[GameTurn]] = {}

        # try to load from sqlite (optional)
        self._load_state_safe()

    # --- public API ---

    def observe_turn(self, conv_id: str, turn: GameTurn) -> None:
        """
        Register one new GameTurn in a given conversation.
        If we have at least 2 previous turns in this conv, update A+B->C stats.
        """
        ...

    def suggest_next(
        self,
        conv_id: str,
        last_turns: Sequence[GameTurn],
        state: Optional["MathState"] = None,
    ) -> Optional[GameHint]:
        """
        Given last two turns in this conversation and current MathState:

        1. Look up best C for (A,B) in transitions.
        2. If missing, fallback to most common single C.
        3. Decode C_id into GameKey and map to GameHint.

        Returns:
            GameHint or None (if no reasonable suggestion).
        """
        ...

    def stats(self) -> Dict[str, float]:
        """Small summary for debugging and tests."""
        return {
            "episode_count": float(self._episode_count),
            "num_pairs": float(len(self._transitions)),
        }

    def save(self) -> None:
        """Persist to sqlite. Silent on failure."""
        self._save_state_safe()

Implementation details:
	•	Use sqlite at state/game.sqlite3, but keep a small in-memory cache for recent transitions.
	•	Use try/except Exception: return in all I/O helpers to protect leo from crashes.
	•	When DB is missing or corrupt → start fresh in-memory.

2.2 Transition structure

In-memory:

# (A_id, B_id) -> Counter({C_id: count})
self._transitions: Dict[Tuple[str, str], Counter[str]] = defaultdict(Counter)

# global singles: most common C overall
self._single: Counter[str] = Counter()

SQLite table proposal:

CREATE TABLE IF NOT EXISTS game_transitions (
    a_id TEXT NOT NULL,
    b_id TEXT NOT NULL,
    c_id TEXT NOT NULL,
    count INTEGER NOT NULL,
    PRIMARY KEY (a_id, b_id, c_id)
);

CREATE TABLE IF NOT EXISTS game_meta (
    key TEXT PRIMARY KEY,
    value TEXT NOT NULL
);

	•	game_meta["episode_count"] holds total number of turns observed (or at least leo’s own episodes), used for “maturity” / max chain length heuristic.

⸻

3. Learning path (observe_turn)

Called after each turn (user or leo) is fully known:

def observe_turn(self, conv_id: str, turn: GameTurn) -> None:
    history = self._last_turns.setdefault(conv_id, [])
    history.append(turn)
    if len(history) > 3:
        history.pop(0)

    self._episode_count += 1

    if len(history) >= 3:
        a, b, c = history[-3], history[-2], history[-1]
        a_id, b_id, c_id = a.to_id(), b.to_id(), c.to_id()
        key = (a_id, b_id)
        self._transitions[key][c_id] += 1
        self._single[c_id] += 1

    # no exceptions should escape; DB persistence is best-effort
    self._save_state_lazy_safe()

	•	Keep last up to 3 turns per conversation in memory (sliding window).
	•	Use simple counts v1; scoring / EMA can be added later if needed.
	•	observe_turn is O(1) per call (aside from occasional lazy save).

Where to call from leo:
	•	For human message:
	•	determine mode = "q" vs "story"/"meta" etc,
	•	approximate MathState from prompt-only metrics (pulse + trauma if available),
	•	set expert="structural", quality="mid",
	•	build GameTurn, call observe_turn(conv_id, turn).
	•	For leo reply:
	•	you already have MathState, themes, expert_name, quality → build GameTurn and call again.

⸻

4. Suggestion path (suggest_next)

Goal: turn (A,B) + current state into GameHint.

def suggest_next(
    self,
    conv_id: str,
    last_turns: Sequence[GameTurn],
    state: Optional["MathState"] = None,
) -> Optional[GameHint]:
    try:
        if len(last_turns) < 2:
            return None

        a_id = last_turns[-2].to_id()
        b_id = last_turns[-1].to_id()
        key = (a_id, b_id)

        counter = self._transitions.get(key)
        if not counter:
            # fallback: global most common C
            if not self._single:
                return None
            c_id, count = self._single.most_common(1)[0]
            confidence = 0.1
        else:
            # sample C proportional to counts
            items = list(counter.items())
            total = sum(c for _, c in items)
            if total <= 0:
                return None
            r = random.uniform(0, total)
            acc = 0.0
            c_id = None
            for cid, w in items:
                acc += w
                if r <= acc:
                    c_id = cid
                    break
            if c_id is None:
                return None
            # basic confidence: how peaked the distribution is
            max_c = max(counter.values())
            confidence = max_c / max(total, 1.0)

        # decode C_id back into GameTurn-like buckets
        c_key = decode_game_id(c_id)  # helper, inverse of GameTurn.to_id

        # map GameKey → GameHint
        hint = self._build_hint_from_key(c_key, state, confidence)
        return hint
    except Exception:
        return None

_build_hint_from_key example mapping:
	•	mode from c_key.mode.
	•	preferred_expert from c_key.expert.
	•	target_length:
	•	"short" if c_key.mode == "ack" or c_key.quality == "low",
	•	"long" if c_key.mode == "story" or c_key.arousal == "high",
	•	else "medium".
	•	tension_shift:
	•	"softer" if c_key.arousal == "low" and c_key.trauma == "high",
	•	"stronger" if c_key.arousal == "high" and c_key.trauma != "low",
	•	"same" otherwise.

Additionally, you can modulate confidence using MathState:
	•	if predicted quality from MathBrain is very low (< 0.3) → shrink confidence (leo is unstable, don’t over-trust game).
	•	if predicted quality is high and entropy in sweet spot → keep confidence.

⸻

5. Chain length / “growth” heuristic

Even if v1 only uses (A,B)→C, we already want a hook for “leo grows, chain length grows”.

Define helper:

def max_trail_length(self) -> int:
    """
    How many steps ahead leo is allowed to think, conceptually.
    v1: only used for diagnostics / future extensions.
    """
    from math import log10

    N = max(self._episode_count, 0)
    base = 2 + int(log10(N + 1))  # slow growth
    return max(2, min(base, 6))

	•	For now this can be just returned in stats() and maybe lightly logged.
	•	In future, when a GameTrail is implemented, this will cap trail length.

Interaction with MathBrain (future):
	•	allow modulating max_trail_length based on predicted quality and entropy:
	•	low predicted quality → effectively cap at 2–3,
	•	high quality & good entropy range → allow 4–6.

For v1, no direct feedback into MathBrain is required — game only consumes MathState.

⸻

6. Integration points in leo.py

Imports with silent fallback:

try:
    from game import GameEngine
    GAME_AVAILABLE = True
except Exception:
    GameEngine = None  # type: ignore
    GAME_AVAILABLE = False

LeoField init:

if GAME_AVAILABLE:
    try:
        self._game = GameEngine(db_path=self.state_dir / "game.sqlite3")
    except Exception:
        self._game = None
else:
    self._game = None

After logging episodes & computing MathState:

For human turn (inside whatever handles user input):

if self._game is not None:
    try:
        math_state = self._build_math_state_for_prompt(prompt_text)
        theme_id = self._dominant_theme_for_prompt(prompt_text)  # or -1
        mode = detect_mode_from_text(prompt_text)  # simple heuristic
        turn = GameTurn.from_context(
            role="human",
            mode=mode,
            math_state=math_state,
            theme_id=theme_id,
            expert="structural",
            quality_value=None,     # -> "mid"
        )
        self._game.observe_turn(conv_id, turn)
    except Exception:
        pass

For leo reply (inside reply() after everything else is computed):

if self._game is not None:
    try:
        turn = GameTurn.from_context(
            role="leo",
            mode=determine_mode_from_reply(reply_text, pulse, trauma_state),
            math_state=math_state,
            theme_id=dominant_theme_id,
            expert=expert_name,
            quality_value=quality_score,
        )
        self._game.observe_turn(conv_id, turn)
    except Exception:
        pass

Before expert routing / generation:

game_hint: Optional[GameHint] = None
if self._game is not None:
    try:
        last_turns = self._game._last_turns.get(conv_id, [])  # or helper API
        game_hint = self._game.suggest_next(conv_id, last_turns, math_state)
    except Exception:
        game_hint = None

Then in expert routing:
	•	if game_hint is not None and game_hint.confidence > 0.3:
	•	bias expert choice towards game_hint.preferred_expert,
	•	adjust target length and temperature by target_length + tension_shift.

If game_hint is None or confidence is low → ignore, use current logic.

⸻

7. Fallback & constraints

Non-negotiable constraints for game.py:
	1.	Optional:
	•	leo must run identically without this module.
	•	Any import / init / DB error → module effectively disabled.
	2.	Silent failure:
	•	All public calls (observe_turn, suggest_next, save) must guard against exceptions.
	•	Errors are NOT printed by default; tests can validate behavior via stats().
	3.	CPU-only & lightweight:
	•	No external frameworks (no PyTorch, no TF).
	•	Only stdlib + sqlite3 (+ numpy optional, but not required).
	4.	No token-level logic:
	•	game.py never inspects raw tokens, bigrams or trigrams.
	•	It only sees GameTurn, MathState, theme ids.
	5.	Advisory, not sovereign:
	•	GameHint is a suggestion.
	•	Final decisions (expert, temperature, length) always stay inside leo.py.

